import os, requests, gspread, json, time, re
from oauth2client.service_account import ServiceAccountCredentials

# ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
WIKI_USER = os.environ['WIKI_USER']
WIKI_PASS = os.environ['WIKI_PASS']
GOOGLE_JSON = os.environ['GOOGLE_CREDENTIALS']
BOT_TOKEN = os.environ.get('DISCORD_BOT_TOKEN')
CHANNEL_ID = os.environ.get('DISCORD_CHANNEL_ID')
SHEET_ID = "1UUZEyqiSk8GBnhSyY-BYNZdc4uutIWD0ggO91oEbKEk"

def send_discord_bot_message(msg):
    if BOT_TOKEN and CHANNEL_ID:
        url = f"https://discord.com/api/v10/channels/{CHANNEL_ID}/messages"
        headers = {"Authorization": f"Bot {BOT_TOKEN}", "Content-Type": "application/json"}
        payload = {"content": msg}
        try: requests.post(url, headers=headers, json=payload)
        except: pass

def run_sync():
    try:
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds_dict = json.loads(GOOGLE_JSON)
        creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        client = gspread.authorize(creds)
        sheet = client.open_by_key(SHEET_ID).get_worksheet(0)

        API_URL = "https://akasauniverse.miraheze.org/w/api.php"
        session = requests.Session()
        session.headers.update({"User-Agent": "WikiDataSync_Final_Details/4.0"})

        # ë¡œê·¸ì¸
        res_t = session.get(API_URL, params={"action": "query", "meta": "tokens", "type": "login", "format": "json"}).json()
        l_token = res_t['query']['tokens']['logintoken']
        session.post(API_URL, data={"action": "login", "lgname": WIKI_USER, "lgpassword": WIKI_PASS, "lgtoken": l_token, "format": "json"})

        all_rows = []
        target_namespaces = [0, 10, 14]
        
        for ns in target_namespaces:
            apcontinue = ""
            while True:
                params = {"action": "query", "list": "allpages", "apnamespace": ns, "aplimit": "50", "format": "json", "apcontinue": apcontinue}
                res = session.get(API_URL, params=params).json()
                pages = res.get('query', {}).get('allpages', [])
                if not pages: break

                pids = [str(p['pageid']) for p in pages]
                p_params = {"action": "query", "pageids": "|".join(pids), "prop": "revisions|images|categories|info", "rvprop": "content", "rvslots": "main", "format": "json"}
                res_p = session.get(API_URL, params=p_params).json()
                pages_detail = res_p.get('query', {}).get('pages', {})

                for pid in pids:
                    p_info = pages_detail.get(pid, {})
                    content = p_info.get('revisions', [{}])[0].get('slots', {}).get('main', {}).get('*', '')
                    
                    # [í•µì‹¬] ì´ë¯¸ì§€ êµ¬ë¬¸ê³¼ ìº¡ì…˜ ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹)
                    # [[íŒŒì¼:ì´ë¦„.png|ì˜µì…˜|ì„¤ëª…]] í˜•íƒœë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
                    img_pattern = re.findall(r'\[\[(?:íŒŒì¼|File|íŒŒì¼):([^|\]]+)(?:\|([^\]]+))?\]\]', content)
                    
                    details_list = []
                    image_titles = []
                    
                    # ë¨¼ì € íŒŒì¼ ì´ë¦„ë“¤ë§Œ ëª¨ì•„ì„œ URL í•œêº¼ë²ˆì— ì¡°íšŒ ì¤€ë¹„
                    for ititle, ioptions in img_pattern:
                        full_name = f"íŒŒì¼:{ititle.strip()}"
                        image_titles.append(full_name)
                    
                    # ì‹¤ì œ URL ì¡°íšŒ
                    url_map = {}
                    if image_titles:
                        img_res = session.get(API_URL, params={"action": "query", "titles": "|".join(image_titles), "prop": "imageinfo", "iiprop": "url", "format": "json"}).json()
                        for img_page in img_res.get('query', {}).get('pages', {}).values():
                            if 'imageinfo' in img_page:
                                url_map[img_page['title']] = img_page['imageinfo'][0]['url']

                    # ë§¤ì¹­ ì‘ì—… (URL + ìº¡ì…˜)
                    for ititle, ioptions in img_pattern:
                        full_name = f"íŒŒì¼:{ititle.strip()}"
                        url = url_map.get(full_name, "")
                        
                        # ì˜µì…˜ ì¤‘ ë§ˆì§€ë§‰ ìš”ì†Œê°€ ë³´í†µ ìº¡ì…˜(ì„¤ëª…)ì„
                        caption = ""
                        if ioptions:
                            opts = ioptions.split('|')
                            # 'ì„¬ë„¤ì¼', 'thumb', 'left' ë“± ì˜ˆì•½ì–´ ì œì™¸í•œ ë§ˆì§€ë§‰ì´ ì„¤ëª…
                            last_opt = opts[-1].strip()
                            if not any(keyword in last_opt for keyword in ['ì„¬ë„¤ì¼', 'thumb', 'left', 'right', 'center', 'px']):
                                caption = last_opt
                        
                        details_list.append({
                            "url": url,
                            "filename": ititle.strip(),
                            "caption": caption
                        })

                    # JSON ë°ì´í„°ì— ìƒì„¸ ë¦¬ìŠ¤íŠ¸ ì‚½ì…
                    p_info['image_details'] = details_list

                    kind = "ì¼ë°˜" if ns == 0 else ("í‹€" if ns == 10 else "ë¶„ë¥˜")
                    cats = p_info.get('categories', [])
                    cat_names = ", ".join([c.get('title', '').replace('ë¶„ë¥˜:', '') for c in cats])

                    raw_json = json.dumps(p_info, ensure_ascii=False)
                    all_rows.append([pid, p_info.get('title', 'N/A'), kind, cat_names, raw_json])

                if 'continue' in res: apcontinue = res['continue']['apcontinue']
                else: break

        # [4] ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
        if all_rows:
            sheet.clear()
            sheet.append_row(["ID", "ì œëª©", "ì¢…ë¥˜", "ë¶„ë¥˜", "JSON"])
            for i in range(0, len(all_rows), 40):
                sheet.append_rows(all_rows[i:i+40])
                time.sleep(1)
            send_discord_bot_message(f"âœ… ë™ê¸°í™” ì™„ë£Œ! ì´ë¯¸ì§€ ìœ„ì¹˜ì™€ ì„¤ëª…ì´ JSONì— í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        send_discord_bot_message(f"ğŸ”¥ ì—ëŸ¬: {str(e)}")

if __name__ == "__main__":
    run_sync()
